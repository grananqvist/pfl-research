{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d449380a-524e-46d8-8cea-f82ddc5460a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.data as dx\n",
    "import numpy as np\n",
    "from pfl.data.dataset import Dataset\n",
    "from mlx.data.datasets import librispeech\n",
    "from mlx.data.datasets.librispeech import load_librispeech_tarfile\n",
    "from mlx.data.core import CharTrie\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "from collections import Counter\n",
    "from pfl.data.federated_dataset import FederatedDataset\n",
    "from pfl.data.pytorch import PyTorchTensorDataset\n",
    "from pfl.data.sampling import MinimizeReuseUserSampler\n",
    "from pfl.model.pytorch import PyTorchModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8170f6d8-c809-498b-b19d-25882a1a0cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeDict(dict):\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = AttributeDict({})\n",
    "args.batch_size = 2\n",
    "args.batch_policy = 'dynamic'\n",
    "args.max_target_len = 100 #400\n",
    "args.threads = 10\n",
    "args.input_key = 'file'\n",
    "args.target_key = 'transcription'\n",
    "args.target_nopad = False\n",
    "args.target_nosil = False\n",
    "args.tar = True\n",
    "args.federated_cohort_size = 10\n",
    "args.local_num_epochs = 1\n",
    "random_seed = 123\n",
    "num_local_devices = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c92a1ec-376b-4d88-8354-58f482ae7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_eng_char_trie_for_ctc(additional_chars):\n",
    "    trie = CharTrie()\n",
    "    trie.insert(\"@\")  # blank\n",
    "    trie.insert(\" \")\n",
    "    trie.insert(\"'\")\n",
    "    for c in range(ord(\"a\"), ord(\"z\") + 1):\n",
    "        trie.insert(chr(c))\n",
    "    if additional_chars:\n",
    "        for c in additional_chars:\n",
    "            trie.insert(c)\n",
    "    return trie\n",
    "\n",
    "\n",
    "def load_librispeech_slices(root=None, split=\"dev-clean\", quiet=False, validate_download=True, trie=None, args=None):\n",
    "    \"\"\"Load the librispeech dataset directly from the TAR archive.\n",
    "\n",
    "    Args:\n",
    "        root (Path or str, optional): The The directory to load/save the data. If\n",
    "            none is given the ``~/.cache/mlx.data/librispeech`` is used.\n",
    "        split (str): The split to use. It should be one of dev-clean,\n",
    "            dev-other, test-clean, test-other, train-clean-100,\n",
    "            train-clean-360, train-other-500 .\n",
    "        quiet (bool): If true do not show download (and possibly decompression)\n",
    "            progress.\n",
    "        args: Additional arguments passed via flags.\n",
    "    \"\"\"\n",
    "    def _to_audio_and_transcript2(sample):\n",
    "        # Split the line\n",
    "        file_part, transcript = bytes(sample[\"sample\"]).split(b\" \", 1)\n",
    "    \n",
    "        # Extract the audio path\n",
    "        parts = file_part.split(b\"-\")\n",
    "        parts[-1] = file_part + b\".flac\"\n",
    "        audio_path = b\"/\".join(parts)\n",
    "    \n",
    "        # Prepare the transcript\n",
    "        transcript = transcript.lower()\n",
    "    \n",
    "        # User id\n",
    "        user_id = int(parts[-3])\n",
    "    \n",
    "        return {\"audio_file\": audio_path, \"transcript\": transcript, \"user_id\": user_id}\n",
    "\n",
    "    \n",
    "    target = load_librispeech_tarfile(\n",
    "        root=root, split=split, quiet=quiet, validate_download=validate_download\n",
    "    )\n",
    "    target = str(target)\n",
    "    prefix = f\"LibriSpeech/{split}\"\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    dset = (\n",
    "        dx.files_from_tar(target)\n",
    "        .to_stream()\n",
    "        .sample_transform(lambda s: s if bytes(s[\"file\"]).endswith(b\".txt\") else dict())\n",
    "        .read_from_tar(target, \"file\", \"samples\", )\n",
    "        .line_reader_from_key(\"samples\", \"sample\", from_memory=True)\n",
    "        .sample_transform(_to_audio_and_transcript2)\n",
    "        .prefetch(args.threads, args.threads)\n",
    "        .to_buffer()\n",
    "        .read_from_tar(target, \"audio_file\", \"audio\", prefix=prefix)\n",
    "        .load_audio(\"audio\", from_memory=True, output_key=\"input\")\n",
    "        .pad_to_multiple(\"input\", 0, 16000, 0, \"input\")\n",
    "        .shape(\"input\", \"input_length\", 0)\n",
    "        .tokenize(\"transcript\", trie, ignore_unk=True, output_key=\"target\")\n",
    "        .shape(\"target\", \"target_length\", 0)\n",
    "        .pad_to_size(\"target\", 0, args.max_target_len, 0)\n",
    "    )\n",
    "\n",
    "    # sort the dataset using user ids and split into batches where each user is a batch\n",
    "    perm = np.argsort([int(x['user_id']) for x in dset])\n",
    "    dset = dset.perm(perm)\n",
    "    user_ids = [int(x['user_id']) for x in dset]\n",
    "    # print('user_ids:', user_ids)\n",
    "    unique_user_ids = np.unique(user_ids)\n",
    "    counter = Counter(user_ids)\n",
    "    batch_sizes = [counter[int(user_id)] for user_id in unique_user_ids]            \n",
    "    dset = dset.batch(batch_sizes)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('preprocessing time:', end - start)\n",
    "    start = time.time()\n",
    "\n",
    "    slices = {}\n",
    "    for item in dset:\n",
    "        user_id = item['user_id'][0]\n",
    "        slices[user_id] = PyTorchTensorDataset(\n",
    "            [torch.Tensor(item['input']), \n",
    "             torch.Tensor(item['target']), \n",
    "             torch.Tensor(item['input_length']), \n",
    "             torch.Tensor(item['target_length'])],\n",
    "            user_id = user_id)\n",
    "\n",
    "    end = time.time()\n",
    "    print('slice processing time:', end - start)\n",
    "    \n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42380788-44fb-42b6-8a47-8705f925787f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: {'batch_size': 2, 'batch_policy': 'dynamic', 'max_target_len': 100, 'threads': 10, 'input_key': 'file', 'target_key': 'transcription', 'target_nopad': False, 'target_nosil': False, 'tar': True, 'federated_cohort_size': 10, 'local_num_epochs': 1}\n",
      "preprocessing time: 6.562301158905029\n",
      "slice processing time: 3.944700002670288\n",
      "total time: 10.510547876358032\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print('args:', args)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "trie = construct_eng_char_trie_for_ctc('')\n",
    "dset=load_librispeech_slices(split='dev-clean', trie=trie, args=args)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('total time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf2cf96-267d-40c2-95ad-6cd343b3326a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 174, 251, 422, 652, 777, 1272, 1462, 1673, 1919, 1988, 1993, 2035, 2078, 2086, 2277, 2412, 2428, 2803, 2902, 3000, 3081, 3170, 3536, 3576, 3752, 3853, 5338, 5536, 5694, 5895, 6241, 6295, 6313, 6319, 6345, 7850, 7976, 8297, 8842]\n",
      "<pfl.data.pytorch.PyTorchTensorDataset object at 0x177ec02e0>\n"
     ]
    }
   ],
   "source": [
    "print(list(dset.keys()))\n",
    "print(dset[1919])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05b599db-57f4-445b-8d43-304c8133bd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch tensor shapes: [torch.Size([5, 432000, 1]), torch.Size([5, 384]), torch.Size([5]), torch.Size([5])]\n",
      "batch tensor shapes: [torch.Size([5, 432000, 1]), torch.Size([5, 384]), torch.Size([5]), torch.Size([5])]\n",
      "batch tensor shapes: [torch.Size([5, 432000, 1]), torch.Size([5, 384]), torch.Size([5]), torch.Size([5])]\n",
      "batch tensor shapes: [torch.Size([5, 432000, 1]), torch.Size([5, 384]), torch.Size([5]), torch.Size([5])]\n",
      "batch tensor shapes: [torch.Size([5, 432000, 1]), torch.Size([5, 384]), torch.Size([5]), torch.Size([5])]\n",
      "batch tensor shapes: [torch.Size([5, 432000, 1]), torch.Size([5, 384]), torch.Size([5]), torch.Size([5])]\n",
      "batch tensor shapes: [torch.Size([5, 432000, 1]), torch.Size([5, 384]), torch.Size([5]), torch.Size([5])]\n",
      "batch tensor shapes: [torch.Size([5, 432000, 1]), torch.Size([5, 384]), torch.Size([5]), torch.Size([5])]\n",
      "batch tensor shapes: [torch.Size([5, 432000, 1]), torch.Size([5, 384]), torch.Size([5]), torch.Size([5])]\n",
      "batch tensor shapes: [torch.Size([5, 432000, 1]), torch.Size([5, 384]), torch.Size([5]), torch.Size([5])]\n",
      "batch tensor shapes: [torch.Size([5, 432000, 1]), torch.Size([5, 384]), torch.Size([5]), torch.Size([5])]\n",
      "batch tensor shapes: [torch.Size([5, 432000, 1]), torch.Size([5, 384]), torch.Size([5]), torch.Size([5])]\n",
      "batch tensor shapes: [torch.Size([4, 432000, 1]), torch.Size([4, 384]), torch.Size([4]), torch.Size([4])]\n"
     ]
    }
   ],
   "source": [
    "# iterate through the batches for the user id 1919\n",
    "for batch in dset[1919].iter(5):\n",
    "    print('batch tensor shapes:', [x.shape for x in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcac4e96-5b12-4b48-9a8d-35fd22c2d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the federated dataset\n",
    "federated_dataset = FederatedDataset.from_slices(dset, user_sampler=MinimizeReuseUserSampler(list(dset.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "351747c2-b5a7-4167-a260-0ddf5a24599c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([65, 320000, 1]), torch.Size([65, 294]), torch.Size([65]), torch.Size([65])]\n",
      "[torch.Size([59, 448000, 1]), torch.Size([59, 307]), torch.Size([59]), torch.Size([59])]\n",
      "[torch.Size([75, 400000, 1]), torch.Size([75, 345]), torch.Size([75]), torch.Size([75])]\n",
      "[torch.Size([36, 528000, 1]), torch.Size([36, 505]), torch.Size([36]), torch.Size([36])]\n",
      "[torch.Size([71, 304000, 1]), torch.Size([71, 319]), torch.Size([71]), torch.Size([71])]\n"
     ]
    }
   ],
   "source": [
    "# iterate through one cohort\n",
    "for client_dataset, _ in federated_dataset.get_cohort(5):\n",
    "    print([x.shape for x in client_dataset.raw_data.raw_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01e0d75d-4b51-443e-8f6f-214d163a7cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([82, 304000, 1]), torch.Size([82, 313]), torch.Size([82]), torch.Size([82])]\n",
      "[torch.Size([73, 480000, 1]), torch.Size([73, 362]), torch.Size([73]), torch.Size([73])]\n",
      "[torch.Size([94, 272000, 1]), torch.Size([94, 251]), torch.Size([94]), torch.Size([94])]\n",
      "[torch.Size([42, 320000, 1]), torch.Size([42, 321]), torch.Size([42]), torch.Size([42])]\n",
      "[torch.Size([64, 432000, 1]), torch.Size([64, 384]), torch.Size([64]), torch.Size([64])]\n"
     ]
    }
   ],
   "source": [
    "# iterate through another cohort\n",
    "for client_dataset, _ in federated_dataset.get_cohort(5):\n",
    "    print([x.shape for x in client_dataset.raw_data.raw_data])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
